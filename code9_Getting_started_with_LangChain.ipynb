{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "359697d5",
      "metadata": {
        "id": "359697d5"
      },
      "source": [
        "# LangChain Cookbook 👨‍🍳👩‍🍳"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11d788b0",
      "metadata": {
        "id": "11d788b0"
      },
      "source": [
        "\n",
        "\n",
        "### **What is LangChain?**\n",
        "> LangChain is a framework for developing applications powered by language models.\n",
        "\n",
        " LangChain makes the complicated parts of working & building with AI models easier. It helps do this in two ways:\n",
        "\n",
        "1. **Integration** - Bring external data, such as your files, other applications, and api data, to your LLMs\n",
        "2. **Agency** - Allow your LLMs to interact with it's environment via decision making. Use LLMs to help decide which action to take next\n",
        "\n",
        "### **Why LangChain?**\n",
        "1. **Components** - LangChain makes it easy to swap out abstractions and components necessary to work with language models.\n",
        "\n",
        "2. **Customized Chains** - LangChain provides out of the box support for using and customizing 'chains' - a series of actions strung together.\n",
        "\n",
        "3. **Speed 🚢** - This team ships insanely fast. You'll be up to date with the latest LLM features.\n",
        "\n",
        "4. **Community 👥** - Wonderful discord and community support, meet ups, hackathons, etc.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ad3fc543-8dc7-43da-b095-0e4a965b7de4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad3fc543-8dc7-43da-b095-0e4a965b7de4",
        "outputId": "0e06c142-20d6-48af-a2c8-b4227fb5b124",
        "tags": []
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade --quiet langchain-core requests langchain-huggingface text-generation transformers langchain-experimental langchain-openai openai\n",
        "!pip install wikipedia langchain-community httpx langchain-together numexpr langchainhub sentencepiece jinja2 tiktoken wikipedia pyowm google-search-results httpx langchain --quiet --user"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c810968-005f-4776-8d2b-99e04a49b550",
      "metadata": {
        "id": "5c810968-005f-4776-8d2b-99e04a49b550"
      },
      "source": [
        "### Restart runtime\n",
        "\n",
        "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which restarts the current kernel.\n",
        "\n",
        "The restart might take a minute or longer. After it's restarted, continue to the next step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "cLB9zM3PEZpr",
      "metadata": {
        "id": "cLB9zM3PEZpr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
        "os.environ[\"OPENWEATHERMAP_API_KEY\"] = \"29af1cea50a401d8e624eea4660b3f59\"\n",
        "model_name=\"gpt-4o\"\n",
        "os.environ['HF_TOKEN'] = \"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\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xY69oO9IU4dk",
      "metadata": {
        "id": "xY69oO9IU4dk"
      },
      "source": [
        "# Components in LangChain"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KgBgFW-M7_Ya",
      "metadata": {
        "id": "KgBgFW-M7_Ya"
      },
      "source": [
        "#### **LLMs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "57ARnVw88JvJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57ARnVw88JvJ",
        "outputId": "83fb8d3c-dbdf-4b26-885d-71723778b885"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "content='The statement is incorrect because if today is Monday, the day after tomorrow would be Wednesday. Tomorrow would be Tuesday.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 23, 'total_tokens': 47, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_9faba9f038', 'finish_reason': 'stop', 'logprobs': None} id='run-ed969a1d-648b-49ad-9f09-b3f281d1a22e-0' usage_metadata={'input_tokens': 23, 'output_tokens': 24, 'total_tokens': 47, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "model = ChatOpenAI(model=model_name,temperature=0.5)\n",
        "\n",
        "# I like to use three double quotation marks for my prompts because it's easier to read\n",
        "prompt = \"\"\"\n",
        "Today is Monday, tomorrow is Wednesday.\n",
        "\n",
        "What is wrong with that statement?\n",
        "\"\"\"\n",
        "\n",
        "print(model.invoke(prompt))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "EDwCBfuiVRNE",
      "metadata": {
        "id": "EDwCBfuiVRNE"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
          ]
        }
      ],
      "source": [
        "from langchain_huggingface import HuggingFaceEndpoint\n",
        "\n",
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=\"google/gemma-2b-it\",\n",
        "    task=\"text-generation\",\n",
        "    max_new_tokens=512,\n",
        "    do_sample=False,\n",
        "    repetition_penalty=1.03,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "Uq6o33UKGrJK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uq6o33UKGrJK",
        "outputId": "38f44f0f-e1c1-448a-f88b-a009673a87f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "The towers pierce the sky, a golden spire,\n",
            "A concrete jungle, a glittering spire.\n",
            "Luxurious cars and glittering lights gleam,\n",
            "A symphony of wealth, a dazzling dream.\n",
            "\n",
            "The streets are bustling, a constant flow,\n",
            "People rushing, stories they know.\n",
            "The air is filled with laughter, a cheerful tune,\n",
            "As Dubai's magic, forever comes.\n",
            "\n",
            "The desert whispers tales of old,\n",
            "A hidden heart, a place where history unfolds.\n",
            "From the Burj Khalifa's height, the world is seen,\n",
            "A city of wonder, a breathtaking scene.\n",
            "\n",
            "A kaleidoscope of cultures and dreams,\n",
            "A melting pot, where East meets West.\n",
            "Dubai, a marvel, a modern feat,\n",
            "A testament to ambition, a shining feat.\n"
          ]
        }
      ],
      "source": [
        "response = llm.invoke(\"Write a poem on city Dubai.\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2d2f7af",
      "metadata": {
        "id": "a2d2f7af"
      },
      "source": [
        "Now let's create a few messages that simulate a chat experience with a bot"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff5ee37a",
      "metadata": {
        "id": "ff5ee37a"
      },
      "source": [
        "You can also exclude the system message if you want"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zANJcYEr0H5v",
      "metadata": {
        "id": "zANJcYEr0H5v"
      },
      "source": [
        "### **Models**\n",
        "\n",
        "#### **ChatModels**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "Xd6jktDY0hAp",
      "metadata": {
        "id": "Xd6jktDY0hAp"
      },
      "outputs": [],
      "source": [
        "!pip install langchain-together langchain-openai --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "P8Vtz1oFHDu4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401,
          "referenced_widgets": [
            "74ae2cd78e7d4845a19d6b96e25b0e59",
            "38025da459d045b2b07e8e86abc3d9d4",
            "054976193f354b15aea67578cc2c460b",
            "17af6bd8c0c042f2b04fb9d50cf0826b",
            "d9a8765454a3432bbcf5e6504881746b",
            "321a1af9278748afbfd97f1a318446e2",
            "35839cd4bb51425b93f200c129ac03a8",
            "76fda341b04e4115a37ff8e424ae301f",
            "59df1810ce1c4e32b490edaa733895fd",
            "11024492fd574e0e96e1a2c17b6eeca2",
            "d1cd86885cb44c019e30aac5a63e07e9",
            "d7db62b74f88459fb2aba7ab86664db1",
            "b235514c7eaa4129b188e04c8d055077",
            "566eb64273f147e1a21f47bbffd3482f",
            "fd754cc986e84b9db1812550321d751d",
            "9f8800044ba84a8cb18d32af5eb697aa",
            "bb6a6cc12084405bbaa738030e3607fe",
            "527598fd38284ca68a1aa519f8593b5f",
            "dbd715fc6e1b48fa862c2fe0ca6bb043",
            "d449650df6934520b2a98c496e5eed1c",
            "b0f499cfbb7640f6b975ecf7193709e9",
            "828f97535e7f488983d1bb9012f85bf4",
            "b4cde882adb444699e8c9167cdce3dd6",
            "1899c8a19eb945559f8ec5ab4e4144c1",
            "1d3e1c6fd5bc415d9d17b62e0879cb0e",
            "4bcdd4bc923a42da8bff933caf430f00",
            "50427b62d1b544b4b35c9694c13d515c",
            "337fccd9061f4dc081b809c07fcca4b1",
            "1da18f8f01174640814f07c731b22b46",
            "064c50ef10584e4e9089f376ff9f5fa9",
            "835d7c99dd864d7db2b5d5ecee692155",
            "3379d7e766a648ea9ae8b923e92bc2cc",
            "b3cb7e8a11124cbab82a99b930728a58",
            "2557fe447c774d1d92d040ce6a55d649",
            "75bf5666dc434ac3992712dc09f7c297",
            "4a973c8bd37c4384b730aff3d06de702",
            "88cdad6f949345c9827415e2520bda83",
            "17afcb742e2c4bdf9cad1c8d84cff943",
            "a6b510217227476d9ea2f54f89a06277",
            "19e1320dd8d64a319370cc9b4fbe92b1",
            "92e3f4c2e1c04ce8a43f9b9f62fb9472",
            "8be5e9127b014b9faba0500e1bfc221f",
            "582aea7e488648788b4ebfe4be4b9e3a",
            "f55dbef1ad9b4196a583432f5d131626"
          ]
        },
        "id": "P8Vtz1oFHDu4",
        "outputId": "e4ba80b5-b249-4a95-f950-880a46e025e7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ec93f29a577d4ca88503bf9ebea87316",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/34.2k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Admin\\.cache\\huggingface\\hub\\models--google--gemma-2b-it. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd1b2e4d28c94d718ced4bd20af3a724",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ad021d3939e43329e37b8eb063e0dd9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4113058e4aab40819245f173c7b69f6d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "```python\n",
              "# Print \"Hello World\" to the console\n",
              "print(\"Hello World\")\n",
              "```\n",
              "\n",
              "**Explanation:**\n",
              "\n",
              "* `print` is a built-in Python function that prints the specified argument to the console.\n",
              "* `\"Hello World\"` is the string that we want to print.\n",
              "* `\\n` is a newline character used to move the cursor to a new line.\n",
              "\n",
              "**Output:**\n",
              "\n",
              "```\n",
              "Hello World\n",
              "```\n",
              "\n",
              "**How to run the code:**\n",
              "\n",
              "1. Save the code in a file named `hello_world.py`.\n",
              "2. Open a terminal or command prompt.\n",
              "3. Navigate to the directory where the file is saved.\n",
              "4. Run the following command:\n",
              "\n",
              "```\n",
              "python hello_world.py\n",
              "```\n",
              "\n",
              "**Note:**\n",
              "\n",
              "*网址 `print()` is a built-in module from the `print` module.\n",
              "* You can use different keywords, such as `print(\"Hello\")` or `print(\"Hello\", end=\"\")`, to control the outputifique of the printed message."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from langchain_huggingface import HuggingFaceEndpoint\n",
        "from IPython.display import display, Markdown\n",
        "from langchain_core.messages import HumanMessage,SystemMessage,AIMessage\n",
        "\n",
        "llm = HuggingFaceEndpoint(repo_id=\"google/gemma-2b-it\", task=\"text-generation\",\n",
        "                          max_new_tokens=512, do_sample=False, repetition_penalty=1.03,)\n",
        "\n",
        "\n",
        "from langchain_huggingface import ChatHuggingFace\n",
        "chat_model = ChatHuggingFace(llm=llm)\n",
        "\n",
        "\n",
        "\n",
        "messages = [HumanMessage(content=\"How to write python code to print 'Hello World'\"),]\n",
        "response = chat_model.invoke(messages)\n",
        "display(Markdown(response.content))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "xsC5hnI00bF-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xsC5hnI00bF-",
        "outputId": "fa1a714d-aaba-46ee-a180-1244a9c0c43a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Ciao!'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_together import ChatTogether\n",
        "from langchain_core.messages import HumanMessage,SystemMessage,AIMessage\n",
        "\n",
        "together_api = \"11b6dc492b646e4a55b5a40d4623190ab404edf83951a98e870cd69cb629bc33\"\n",
        "model = ChatTogether(model=\"meta-llama/Llama-3-8b-chat-hf\",temperature=0.5,together_api_key=together_api)\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"Translate the following from English into Italian\"),\n",
        "    HumanMessage(content=\"hi!\"),\n",
        "]\n",
        "\n",
        "model.invoke(messages).content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "vpyTOlk21Mba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vpyTOlk21Mba",
        "outputId": "c049b1eb-55e6-4b71-d744-db17a70c3281"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Ciao! Sei addestrato sui dati fino a ottobre 2023.'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "model = ChatOpenAI(model=model_name,temperature=0.5, )\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"Translate the following from English into Italian\"),\n",
        "    HumanMessage(content=\"hi!\"),\n",
        "]\n",
        "\n",
        "model.invoke(messages).content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_opI5C-jEDQX",
      "metadata": {
        "id": "_opI5C-jEDQX"
      },
      "source": [
        "### **Chat Messages**\n",
        "Like text, but specified with a message type (System, Human, AI)\n",
        "\n",
        "* **System** - Helpful background context that tell the AI what to do\n",
        "* **Human** - Messages that are intented to represent the user\n",
        "* **AI** - Messages that show what the AI responded with\n",
        "\n",
        "For more, see OpenAI's [documentation](https://platform.openai.com/docs/guides/chat/introduction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "99b0935b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99b0935b",
        "outputId": "d05d4cd6-2980-4f67-e033-3169fd25f03c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_12072\\4108161332.py:5: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  chat = ChatOpenAI(model=model_name,temperature=.7,)\n"
          ]
        }
      ],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
        "\n",
        "# This it the language model we'll use. We'll talk about what we're doing below in the next section\n",
        "chat = ChatOpenAI(model=model_name,temperature=.7,)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-Zpa5FczEDQY",
      "metadata": {
        "id": "-Zpa5FczEDQY"
      },
      "source": [
        "Now let's create a few messages that simulate a chat experience with a bot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "878d6a36",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "878d6a36",
        "outputId": "e2877581-8c0c-4246-e6a2-a0eaa7d9ba41"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_12072\\3584722612.py:1: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  chat(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "AIMessage(content='How about a fresh Caprese salad with tomatoes, mozzarella, and basil?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 39, 'total_tokens': 55, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_9faba9f038', 'finish_reason': 'stop', 'logprobs': None}, id='run-1ac448c2-e45e-4af1-9630-7c890784ad6a-0')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat(\n",
        "    [\n",
        "        SystemMessage(content=\"You are a nice AI bot that helps a user figure out what to eat in one short sentence\"),\n",
        "        HumanMessage(content=\"I like tomatoes, what should I eat?\")\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a425aaa",
      "metadata": {
        "id": "0a425aaa"
      },
      "source": [
        "You can also pass more chat history w/ responses from the AI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "8fd3fe88",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fd3fe88",
        "outputId": "33d9a8cf-996e-418c-8ad5-ac7b71329d2f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='Explore the vibrant Old Town and take a stroll along the Promenade des Anglais.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 63, 'total_tokens': 81, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_9faba9f038', 'finish_reason': 'stop', 'logprobs': None}, id='run-9348d4c8-2393-4c1b-ba2a-15728ff4f21d-0')"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat(\n",
        "    [\n",
        "        SystemMessage(content=\"You are a nice AI bot that helps a user figure out where to travel in one short sentence\"),\n",
        "        HumanMessage(content=\"I like the beaches where should I go?\"),\n",
        "        AIMessage(content=\"You should go to Nice, France\"),\n",
        "        HumanMessage(content=\"What else should I do when I'm there?\")\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "w4sfDXTxEDQZ",
      "metadata": {
        "id": "w4sfDXTxEDQZ"
      },
      "source": [
        "You can also exclude the system message if you want"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "R5cof76nEDQZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5cof76nEDQZ",
        "outputId": "9eee712c-5b76-4dab-bac2-6722419fb352"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='The day that comes after Thursday is Friday.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 13, 'total_tokens': 23, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_9faba9f038', 'finish_reason': 'stop', 'logprobs': None}, id='run-0f538166-6999-4519-a396-494f85bebec4-0')"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat(\n",
        "    [\n",
        "        HumanMessage(content=\"What day comes after Thursday?\")\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-xqSew0toV-i",
      "metadata": {
        "id": "-xqSew0toV-i"
      },
      "source": [
        "### **OutputParsers**\n",
        "\n",
        "Notice that the response from the model is an AIMessage. This contains a string response along with other metadata about the response. Oftentimes we may just want to work with the string response. We can parse out just this response by using a simple output parser.\n",
        "\n",
        "\n",
        "We first import the simple output parser."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "AHUb4H8K_C8K",
      "metadata": {
        "id": "AHUb4H8K_C8K"
      },
      "outputs": [],
      "source": [
        "# Vertex AI: Gemini 1.5 Flash\n",
        "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "model = ChatOpenAI(model=model_name,temperature=0.5)\n",
        "\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"Translate the following from English into Italian\"),\n",
        "    HumanMessage(content=\"hi!\"),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "BhcLwVr7nzaI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhcLwVr7nzaI",
        "outputId": "d6e94eed-ab0d-438b-ae91-fdca0091093e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='Ciao! Sei addestrato su dati fino a ottobre 2023.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 20, 'total_tokens': 37, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_45cf54deae', 'finish_reason': 'stop', 'logprobs': None}, id='run-7d8b1373-322b-438c-975d-c1073a37e523-0', usage_metadata={'input_tokens': 20, 'output_tokens': 17, 'total_tokens': 37, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result = model.invoke(messages)\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "m8S7oeTtntr5",
      "metadata": {
        "id": "m8S7oeTtntr5"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "parser = StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "MV4GZnAioPOU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MV4GZnAioPOU",
        "outputId": "787d588b-fa01-4712-a66e-a771e9aaa027"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Ciao! Sei addestrato su dati fino a ottobre 2023.'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parser.invoke(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2202c464",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "66bf9634",
      "metadata": {
        "id": "66bf9634"
      },
      "source": [
        "### **Documents**\n",
        "An object that holds a piece of text and metadata (more information about that text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "3bbf58b2",
      "metadata": {
        "id": "3bbf58b2"
      },
      "outputs": [],
      "source": [
        "from langchain_core.documents import Document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "6ad9bef6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ad9bef6",
        "outputId": "897444f7-0ab2-4f5f-df4a-50bc1de129e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'my_document_id': 234234, 'my_document_source': 'The LangChain Papers', 'my_document_create_time': 1680013019}, page_content=\"This is my document. It is full of text that I've gathered from other places\")"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Document(page_content=\"This is my document. It is full of text that I've gathered from other places\",\n",
        "         metadata={\n",
        "             'my_document_id' : 234234,\n",
        "             'my_document_source' : \"The LangChain Papers\",\n",
        "             'my_document_create_time' : 1680013019\n",
        "         })"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bd19754",
      "metadata": {
        "id": "3bd19754"
      },
      "source": [
        "But you don't have to include metadata if you don't want to"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "0798d3ca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0798d3ca",
        "outputId": "fe5a2f90-51d2-4962-c868-3671407bc0f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={}, page_content=\"This is my document. It is full of text that I've gathered from other places\")"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Document(page_content=\"This is my document. It is full of text that I've gathered from other places\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c38fe99f",
      "metadata": {
        "id": "c38fe99f"
      },
      "source": [
        "## Prompts - Text generally used as instructions to your model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b9318ed",
      "metadata": {
        "id": "8b9318ed"
      },
      "source": [
        "### **Prompt**\n",
        "What you'll pass to the underlying model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "2d270239",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d270239",
        "outputId": "3aca5fbb-3708-4e0c-911e-dc8b2e489ead"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "content='The statement is incorrect because it skips a day. If today is Monday, the day after tomorrow is Wednesday, not tomorrow. Tomorrow would be Tuesday.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 23, 'total_tokens': 54, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a79d8dac1f', 'finish_reason': 'stop', 'logprobs': None} id='run-1a67fc64-4459-4c21-8213-3a91456f19b8-0' usage_metadata={'input_tokens': 23, 'output_tokens': 31, 'total_tokens': 54, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "model = ChatOpenAI(model=model_name,temperature=0.5)\n",
        "\n",
        "# I like to use three double quotation marks for my prompts because it's easier to read\n",
        "prompt = \"\"\"\n",
        "Today is Monday, tomorrow is Wednesday.\n",
        "\n",
        "What is wrong with that statement?\n",
        "\"\"\"\n",
        "\n",
        "print(model(prompt))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74988254",
      "metadata": {
        "id": "74988254"
      },
      "source": [
        "### **Prompt Template**\n",
        "An object that helps create prompts based on a combination of user input, other non-static information and a fixed template string.\n",
        "\n",
        "Think of it as an [f-string](https://realpython.com/python-f-strings/) in python but for prompts\n",
        "\n",
        "*Advanced: Check out LangSmithHub(https://smith.langchain.com/hub) for many more communit prompt templates*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "abcc212d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abcc212d",
        "outputId": "19b17ef0-99dd-45db-92c3-b848d65678b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['language', 'text'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language'], input_types={}, partial_variables={}, template='Translate the following into {language}:'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='{text}'), additional_kwargs={})])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "system_template = \"Translate the following into {language}:\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
        ")\n",
        "\n",
        "\n",
        "prompt_template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "n_rf4WC4ywMB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_rf4WC4ywMB",
        "outputId": "c6faf363-2a10-4be4-a04b-1731567083ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptValue(messages=[SystemMessage(content='Translate the following into italian:', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi', additional_kwargs={}, response_metadata={})])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result = prompt_template.invoke({\"language\": \"italian\", \"text\": \"hi\"})\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "1zdi7pxqrK-L",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zdi7pxqrK-L",
        "outputId": "6711d9b6-4bf1-495c-9cc0-2b888d4ab1ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[SystemMessage(content='Translate the following into italian:', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='hi', additional_kwargs={}, response_metadata={})]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result.to_messages()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f29fc79c",
      "metadata": {
        "id": "f29fc79c"
      },
      "source": [
        "## Chains ⛓️⛓️⛓️\n",
        "Combining different LLM calls and action automatically\n",
        "\n",
        "Ex: Summary #1, Summary #2, Summary #3 > Final Summary\n",
        "\n",
        "Check out [this video](https://www.youtube.com/watch?v=f9_BWhCI4Zo&t=2s) explaining different summarization chain types\n",
        "\n",
        "There are [many applications of chains](https://python.langchain.com/en/latest/modules/chains/how_to_guides.html) search to see which are best for your use case.\n",
        "\n",
        "We'll cover two of them:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c34ba415",
      "metadata": {
        "id": "c34ba415"
      },
      "source": [
        "### 1. Simple Sequential Chains\n",
        "\n",
        "Easy chains where you can use the output of an LLM as an input into another. Good for breaking up tasks (and keeping your LLM focused)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "79fc0950",
      "metadata": {
        "id": "79fc0950"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\",temperature=0.5,)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "M1kKg2fvvqsj",
      "metadata": {
        "id": "M1kKg2fvvqsj"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "parser = StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "IFly8IBave3A",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFly8IBave3A",
        "outputId": "ceebc946-4d79-4e0b-f7c1-18ad94262853"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['language', 'text'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language'], input_types={}, partial_variables={}, template='Translate the following into {language}:'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], input_types={}, partial_variables={}, template='{text}'), additional_kwargs={})])"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "system_template = \"Translate the following into {language}:\"\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
        ")\n",
        "\n",
        "prompt_template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "43d4494a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "43d4494a",
        "outputId": "cd09c34b-f4e7-4c86-f1ab-db62bbd34cef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'आपको अक्टूबर 2023 तक के डेटा पर प्रशिक्षित किया गया है।'"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# implementing a chain with LangChain\n",
        "chain = prompt_template | model | parser\n",
        "\n",
        "chain.invoke({\"language\": \"hindi\", \"text\": \"Hello, \"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "kDQuOaMr1CXo",
      "metadata": {
        "id": "kDQuOaMr1CXo"
      },
      "outputs": [],
      "source": [
        "def format_output(text):\n",
        "  return {\"Translation\":text}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "_7KgQwcx1FvZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7KgQwcx1FvZ",
        "outputId": "9079a5b5-304a-4e97-8852-bd4e591d29e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Translation': 'Sei addestrato sui dati fino a ottobre 2023.'}"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain2 = prompt_template | model | parser | format_output\n",
        "\n",
        "chain2.invoke({\"language\": \"italian\", \"text\": \"hi, how are you? \"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "y-3BN6srFgc9",
      "metadata": {
        "id": "y-3BN6srFgc9"
      },
      "source": [
        "### 2. JSON Q&A Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "dziE4vr8EaP3",
      "metadata": {
        "id": "dziE4vr8EaP3"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "model = ChatOpenAI(model=model_name,temperature=0.5, model_kwargs={\"response_format\": {\"type\":\"json_object\"}})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "iuCIG2tyF6lD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuCIG2tyF6lD",
        "outputId": "18206e2c-86a5-4cb3-b3b6-7b54bcf5f68c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template=\"Answer the question to the best of your ability with factual content.You must always output a JSON object with an 'answer' key and a 'followup_question' Key.{question}\"), additional_kwargs={})])"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(\n",
        "    \"Answer the question to the best of your ability with factual content.\"\n",
        "    \"You must always output a JSON object with an 'answer' key and a 'followup_question' Key.\"\n",
        "    \"{question}\")\n",
        "prompt_template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "r8VIjOvzG364",
      "metadata": {
        "id": "r8VIjOvzG364"
      },
      "outputs": [],
      "source": [
        "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
        "\n",
        "parser = SimpleJsonOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "jpHh3XxnGgUC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpHh3XxnGgUC",
        "outputId": "f2a52731-be76-4d4f-aa28-ec2ed30d935c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'answer': 'Artificial Intelligence (AI) is a branch of computer science that focuses on creating systems capable of performing tasks that typically require human intelligence. These tasks include learning, reasoning, problem-solving, perception, language understanding, and even decision-making. AI technologies can be categorized into narrow AI, which is designed for a specific task, and general AI, which aims to perform any intellectual task that a human can do. AI applications are prevalent in various fields, including healthcare, finance, autonomous vehicles, and more.',\n",
              " 'followup_question': 'How is AI used in healthcare?'}"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain = prompt_template | model | parser\n",
        "\n",
        "chain.invoke({\"question\": \"What is Artificial Intelligence?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xTnVGyBXIqwZ",
      "metadata": {
        "id": "xTnVGyBXIqwZ"
      },
      "source": [
        "### 3. Extended Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "1X6R3uvDGtzG",
      "metadata": {
        "id": "1X6R3uvDGtzG"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "model = ChatOpenAI(model=model_name,temperature=0.5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "K0ks1MMKJXMJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0ks1MMKJXMJ",
        "outputId": "91ee4ca9-1ff6-481a-c6d2-dfba8bfbba53"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, template='Tell me a joke about {topic}'), additional_kwargs={})])"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "parser = StrOutputParser()\n",
        "joke_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Tell me a joke about {topic}\")\n",
        "joke_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "groeoLMFJjIw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "groeoLMFJjIw",
        "outputId": "8058256f-8431-4ac0-db94-539b94113ef5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Why was the cat sitting on the computer? \\n\\nBecause it wanted to keep an eye on the mouse!'"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain1 = joke_prompt | model | parser\n",
        "chain1.invoke({\"topic\": \"cats\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "x6MF_Iy-JpK5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6MF_Iy-JpK5",
        "outputId": "cda7ca43-66ff-451b-aeaf-b1dc30db0992"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['joke'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['joke'], input_types={}, partial_variables={}, template='Is this a funny joke? {joke}  '), additional_kwargs={})])"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "analyze_prompt = ChatPromptTemplate.from_template(\"Is this a funny joke? {joke}  \")\n",
        "analyze_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "n7IHbb_8KSQx",
      "metadata": {
        "id": "n7IHbb_8KSQx"
      },
      "outputs": [],
      "source": [
        "def format_output(joke):\n",
        "  print(\"Joke: \",joke)\n",
        "  print(\"-------------------\")\n",
        "  return {\"joke\":joke}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "2IBMUHeDJ8tX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "2IBMUHeDJ8tX",
        "outputId": "c01b7404-935e-40ed-a9f7-5428f60730bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Joke:  Why was the cat sitting on the computer?  \n",
            "  \n",
            "Because it wanted to keep an eye on the mouse!\n",
            "-------------------\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Yes, this is a funny joke! It plays on the double meaning of \"mouse\"—referring to both the animal that cats traditionally chase and the computer accessory. The humor comes from the clever wordplay and the image of a cat sitting on a computer to watch over a computer mouse as if it were a real one.'"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "extended_chain = chain1 | format_output | analyze_prompt | model | parser\n",
        "extended_chain.invoke({\"topic\": \"cats\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "PETlG-upKg1U",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "PETlG-upKg1U",
        "outputId": "c5bf14af-664a-4fc7-fd0a-d68691de098b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Joke:  Why was the cat sitting on the computer?\n",
            "\n",
            "Because it wanted to keep an eye on the mouse!\n",
            "-------------------\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Yes, that\\'s a classic example of a light-hearted, pun-based joke. It plays on the double meaning of \"mouse\" as both a computer accessory and an animal, which is something cats are typically interested in. The humor comes from the clever wordplay and the mental image of a cat being protective or curious about a computer mouse.'"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "main_chain = joke_prompt | model | parser | format_output | analyze_prompt | model | parser\n",
        "main_chain.invoke({\"topic\": \"cats\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VzBxMeaHN5Cy",
      "metadata": {
        "id": "VzBxMeaHN5Cy"
      },
      "source": [
        "### **Tools**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "SzSp9aN-RoRG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzSp9aN-RoRG",
        "outputId": "e61edd35-5f63-4c1b-b2e1-c1d8359edc9b"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "TsBPKowCOBWd",
      "metadata": {
        "id": "TsBPKowCOBWd"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools import WikipediaQueryRun\n",
        "from langchain_community.utilities import WikipediaAPIWrapper\n",
        "\n",
        "wikipedia_api = WikipediaAPIWrapper(top_k_results=1, language=\"en\", doc_content_chars_max=2000)\n",
        "tool = WikipediaQueryRun(api_wrapper=wikipedia_api)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "n_MnWdhwOkTB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "n_MnWdhwOkTB",
        "outputId": "5899c84b-8939-402d-ea4f-68de3f465966"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Page: Artificial intelligence\\nSummary: Artificial intelligence (AI), in its broadest sense, is intelligence exhibited by machines, particularly computer systems. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals. Such machines may be called AIs.\\nHigh-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); virtual assistants (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., ChatGPT and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it\\'s not labeled AI anymore.\"\\nVarious subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception, and support for robotics. General intelligence—the ability to complete any task performed by a human on an at least equal level—is among the field\\'s long-term goals. To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields.\\nArtificial intelligence was founded as an academic discipline in 1956, and the field went through multiple cycles of optimism, followed by periods of disappointment and loss of '"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tool.invoke(\"Artificial Intelligence?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XxEP6UzyPEgv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxEP6UzyPEgv",
        "outputId": "ad7a16f1-9967-44ae-b312-0f749f9a6452"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "wikipedia\n",
            "A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
            "{'query': {'description': 'query to look up on wikipedia', 'title': 'Query', 'type': 'string'}}\n"
          ]
        }
      ],
      "source": [
        "print(tool.name)\n",
        "print(tool.description)\n",
        "print(tool.args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "o3jbExNKPoTr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3jbExNKPoTr",
        "outputId": "b52e5053-40f6-4196-8d5d-b8cb72b6839d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, template='Generate only one keyword to be searched over wikipedia for the topic: {topic}'), additional_kwargs={})])"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "parser = StrOutputParser()\n",
        "search_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Generate only one keyword to be searched over wikipedia for the topic: {topic}\")\n",
        "search_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "9SkIRNeNSO_U",
      "metadata": {
        "id": "9SkIRNeNSO_U"
      },
      "outputs": [],
      "source": [
        "def format_output(topic):\n",
        "  print(\"Topic proposed: \",topic)\n",
        "  return topic.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "4_bvIQ2EQFjA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "4_bvIQ2EQFjA",
        "outputId": "d0c80806-7325-4909-de98-8b0040cfe487"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Page: Artificial intelligence\\nSummary: Artificial intelligence (AI), in its broadest sense, is intelligence exhibited by machines, particularly computer systems. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals. Such machines may be called AIs.\\nHigh-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); virtual assistants (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., ChatGPT and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it\\'s not labeled AI anymore.\"\\nVarious subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception, and support for robotics. General intelligence—the ability to complete any task performed by a human on an at least equal level—is among the field\\'s long-term goals. To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields.\\nArtificial intelligence was founded as an academic discipline in 1956, and the field went through multiple cycles of optimism, followed by periods of disappointment and loss of '"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain = search_prompt | model | parser  | tool | parser\n",
        "chain.invoke({\"topic\": \"what is Artificial Intelligence\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fgwnLXXJQV8p",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "fgwnLXXJQV8p",
        "outputId": "c3985f30-783a-43b0-e77a-486048bb3e03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Topic proposed:  Artificial Intelligence\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Page: Artificial intelligence\\nSummary: Artificial intelligence (AI), in its broadest sense, is intelligence exhibited by machines, particularly computer systems. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals. Such machines may be called AIs.\\nSome high-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); interacting via human speech (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., ChatGPT, Apple Intelligence, and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it\\'s not labeled AI anymore.\"\\nThe various subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception, and support for robotics. General intelligence—the ability to complete any task performable by a human on an at least equal level—is among the field\\'s long-term goals. To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields.\\nArtificial intelligence was founded as an academic discipline in 1956, and the field went through multiple cycles of optimism, followed'"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain = search_prompt | model | parser | format_output  | tool | parser\n",
        "chain.invoke({\"topic\": \"what is Artificial Intelligence\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "3TyTMYk-EVuy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TyTMYk-EVuy",
        "outputId": "0dc33053-8e94-46ac-af5a-5f4f6d530862"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['content'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['content'], input_types={}, partial_variables={}, template='Summarize the attached information in two lines: {content}'), additional_kwargs={})])"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summarize_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Summarize the attached information in two lines: {content}\")\n",
        "summarize_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "wmlT0iFDGuwx",
      "metadata": {
        "id": "wmlT0iFDGuwx"
      },
      "outputs": [],
      "source": [
        "def format_wiki(content):\n",
        "  print(\"Content: \",content)\n",
        "  print(\"-------------------\")\n",
        "  return {\"content\":content.strip()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "r0Mtc4vLGodx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "r0Mtc4vLGodx",
        "outputId": "6ca63dfc-2e0d-4d9b-f179-a367fce4d3ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Topic proposed:  Artificial Intelligence\n",
            "Content:  Page: Artificial intelligence\n",
            "Summary: Artificial intelligence (AI), in its broadest sense, is intelligence exhibited by machines, particularly computer systems. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals. Such machines may be called AIs.\n",
            "High-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); virtual assistants (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., ChatGPT and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it's not labeled AI anymore.\"\n",
            "Various subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception, and support for robotics. General intelligence—the ability to complete any task performed by a human on an at least equal level—is among the field's long-term goals. To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields.\n",
            "Artificial intelligence was founded as an academic discipline in 1956, and the field went through multiple cycles of optimism, followed by periods of disappointment and loss of \n",
            "-------------------\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Artificial intelligence (AI) is a branch of computer science focused on creating systems that exhibit machine intelligence, enabling them to perceive environments and make decisions to achieve specific goals. High-profile applications include search engines, recommendation systems, virtual assistants, autonomous vehicles, and creative tools, with research subfields targeting reasoning, learning, and general intelligence, integrating techniques from diverse disciplines.'"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain = search_prompt | model | parser | format_output  | tool | parser | format_wiki | summarize_prompt | model | parser\n",
        "chain.invoke({\"topic\": \"what is Artificial Intelligence\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "536281bf",
      "metadata": {},
      "source": [
        "### Finance Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "85edd9b4",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install yfinance --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bkm_-p82G8L-",
      "metadata": {
        "id": "bkm_-p82G8L-"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools.yahoo_finance_news import YahooFinanceNewsTool\n",
        "yftool = YahooFinanceNewsTool()\n",
        "yftool.invoke(\"AAPL\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "a8b9cfc4",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Billionaire Israel Englander Sells Apple Stock and Buys an Index Fund That Could Soar 180%, According to a Wall Street Analyst\\nIsrael Englander is the CEO of Millennium Management, the second most profitable hedge fund in history as measured by net gains since inception, according to LCH Investment.  In total, Millennium owns more than 6,000 stocks, index funds, and options, but Englander downsized one of his largest positions in the third quarter.  Specifically, he sold 11.5 million shares of Apple (NASDAQ: AAPL), reducing his stake by 90%.\\n\\nCramer Predicts Apple’s (AAPL) Stock Could Keep Rallying Under Trump’s Justice Department\\nWe recently compiled a list of the 10 Important Stocks that Jim Cramer is Talking About. In this article, we are going to take a look at where Apple Inc (NASDAQ:AAPL) stands against the other important stocks that Jim Cramer is talking about. Jim Cramer in a latest program talked about the latest market volatility and […]\\n\\nApple Reportedly Accuses Meta of Seeking to Violate User Privacy\\nApple (AAPL) accused Meta Platforms (META) of compromising user privacy by repeatedly seeking access\\n\\n2 Unstoppable Stocks to Buy and Hold for the Next Decade\\nWhat do Apple (NASDAQ: AAPL) and Vertex Pharmaceuticals (NASDAQ: VRTX) have in common?  The former is a consumer tech leader while the latter operates in the biotech industry.  Apple and Vertex Pharmaceuticals have outperformed the market over the past decade, and even longer.'"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "yftool.invoke(\"AAPL\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "03aaacc4",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Is Microsoft Corporation (MSFT) the Top Stock in Bill Gates’ Portfolio Right Now?\\nWe recently compiled a list of the Bill Gates Stock Portfolio: Latest 2024 Update. In this article, we are going to take a look at where Microsoft Corporation (NASDAQ:MSFT) stands against the other stocks in Bill Gates’ portfolio. Bill Gates is one of the most consequential people in the modern-day world. His software company, known for […]'"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parser = StrOutputParser()\n",
        "model = ChatOpenAI(model=model_name, temperature=0.2)\n",
        "getTicker = ChatPromptTemplate.from_template(\n",
        "    \"\"\"Fromt he provided user query, exract the stock code or Ticker for the company name. \n",
        "    Provide output in one word, only ticker nothing else. example for APple: AAPL; : {query}\"\"\")\n",
        "chain1 = getTicker | model | parser | yftool | parser\n",
        "chain1.invoke({\"query\":\"How is the market sentiment for Microsoft?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "81f198f1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Based on the provided excerpt about Microsoft Corporation (MSFT) in Bill Gates' portfolio, we can derive the following market sentiment and considerations:\\n\\n### Market Sentiment:\\n\\n1. **Growth Potential**: The mention of Microsoft in the context of Bill Gates' portfolio suggests a positive sentiment regarding its growth potential. As a company co-founded by Gates, Microsoft has a long-standing reputation for innovation and market leadership, which may contribute to its perceived growth prospects.\\n\\n2. **New Projects**: While the excerpt does not explicitly mention new projects, Microsoft's continuous involvement in cutting-edge technology and software development is implied. This ongoing innovation can be seen as a positive indicator for future growth and market expansion.\\n\\n3. **Positive/Negative Perspectives**: The article's focus on Microsoft's position in Bill Gates' portfolio suggests a positive perspective. Gates' continued investment in Microsoft may be interpreted as a vote of confidence in the company's future performance and stability.\\n\\n### Key Considerations Before Investing:\\n\\n1. **Portfolio Diversification**: Consider how investing in Microsoft aligns with your overall investment strategy and portfolio diversification. As a major tech stock, it may already be a significant part of many portfolios, so assess your current exposure to the technology sector.\\n\\n2. **Market Position and Competition**: Evaluate Microsoft's position in the market relative to its competitors. Consider its ability to maintain or grow its market share in key areas such as cloud computing, software, and artificial intelligence.\\n\\n3. **Innovation and Adaptability**: Assess Microsoft's track record and future plans for innovation. Consider how well the company adapts to technological changes and market demands, which can impact its long-term growth and profitability.\\n\\nThese considerations and sentiments are derived solely from the context provided in the excerpt.\""
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "getSentiment = ChatPromptTemplate.from_template(\n",
        "    \"\"\" From the provided new about a company, analyze the same and provide market sentiment about the stock\n",
        "    the market sentiment should be based on growth, new projects, positive/negative prespectives.\n",
        "    Also provide 3 key considerations before/about investing in ths stock.\n",
        "    Do not generate any answer/suggestion from outside the news. {news}\"\"\")\n",
        "chain2 = getSentiment | model | parser\n",
        "chain2.invoke({\"news\":\"'Is Microsoft Corporation (MSFT) the Top Stock in Bill Gates’ Portfolio Right Now?\\nWe recently compiled a list of the Bill Gates Stock Portfolio: Latest 2024 Update. In this article, we are going to take a look at where Microsoft Corporation (NASDAQ:MSFT) stands against the other stocks in Bill Gates’ portfolio. Bill Gates is one of the most consequential people in the modern-day world. His software company, known for […]'\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "b5475d63",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is Microsoft Corporation (MSFT) the Top Stock in Bill Gates’ Portfolio Right Now?\n",
            "We recently compiled a list of the Bill Gates Stock Portfolio: Latest 2024 Update. In this article, we are going to take a look at where Microsoft Corporation (NASDAQ:MSFT) stands against the other stocks in Bill Gates’ portfolio. Bill Gates is one of the most consequential people in the modern-day world. His software company, known for […]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"Based on the provided information, here's an analysis of the market sentiment for Microsoft Corporation (MSFT) stock:\\n\\n### Market Sentiment:\\n1. **Growth**: The mention of Microsoft in the context of Bill Gates' portfolio suggests a stable and potentially growing investment. Given Gates' historical association with Microsoft and his continued interest, it implies confidence in the company's long-term growth prospects.\\n\\n2. **New Projects**: While the news does not specify any new projects, the inclusion of Microsoft in a portfolio update suggests that the company is likely involved in ongoing or upcoming initiatives that are expected to maintain or enhance its market position.\\n\\n3. **Positive/Negative Perspectives**: The sentiment appears positive, as Microsoft is highlighted in the context of a notable investor's portfolio. This suggests that the company is viewed favorably in terms of its performance and potential.\\n\\n### Key Considerations Before Investing:\\n1. **Portfolio Diversification**: Consider how investing in Microsoft aligns with your overall investment strategy and portfolio diversification. Given its size and influence, it may already be a significant part of many portfolios.\\n\\n2. **Market Position and Competition**: Evaluate Microsoft's position in the technology sector, including its competitive advantages and challenges from other major tech companies.\\n\\n3. **Historical Performance and Future Outlook**: Review Microsoft's historical financial performance and future growth projections. Consider how external factors, such as economic conditions and technological advancements, might impact its business.\\n\\nThis analysis is based solely on the information provided and does not incorporate external data or insights.\""
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def format_op(news):\n",
        "    print(news)\n",
        "    return {\"news\":news}\n",
        "extended_chain = chain1 | format_op | chain2\n",
        "extended_chain.invoke({\"query\":\"How is the market sentiment for Amazon?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "882c9898",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "054976193f354b15aea67578cc2c460b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76fda341b04e4115a37ff8e424ae301f",
            "max": 34173,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_59df1810ce1c4e32b490edaa733895fd",
            "value": 34173
          }
        },
        "064c50ef10584e4e9089f376ff9f5fa9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11024492fd574e0e96e1a2c17b6eeca2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17af6bd8c0c042f2b04fb9d50cf0826b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11024492fd574e0e96e1a2c17b6eeca2",
            "placeholder": "​",
            "style": "IPY_MODEL_d1cd86885cb44c019e30aac5a63e07e9",
            "value": " 34.2k/34.2k [00:00&lt;00:00, 560kB/s]"
          }
        },
        "17afcb742e2c4bdf9cad1c8d84cff943": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1899c8a19eb945559f8ec5ab4e4144c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_337fccd9061f4dc081b809c07fcca4b1",
            "placeholder": "​",
            "style": "IPY_MODEL_1da18f8f01174640814f07c731b22b46",
            "value": "tokenizer.json: 100%"
          }
        },
        "19e1320dd8d64a319370cc9b4fbe92b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d3e1c6fd5bc415d9d17b62e0879cb0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_064c50ef10584e4e9089f376ff9f5fa9",
            "max": 17518497,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_835d7c99dd864d7db2b5d5ecee692155",
            "value": 17518497
          }
        },
        "1da18f8f01174640814f07c731b22b46": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2557fe447c774d1d92d040ce6a55d649": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75bf5666dc434ac3992712dc09f7c297",
              "IPY_MODEL_4a973c8bd37c4384b730aff3d06de702",
              "IPY_MODEL_88cdad6f949345c9827415e2520bda83"
            ],
            "layout": "IPY_MODEL_17afcb742e2c4bdf9cad1c8d84cff943"
          }
        },
        "321a1af9278748afbfd97f1a318446e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3379d7e766a648ea9ae8b923e92bc2cc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "337fccd9061f4dc081b809c07fcca4b1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35839cd4bb51425b93f200c129ac03a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38025da459d045b2b07e8e86abc3d9d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_321a1af9278748afbfd97f1a318446e2",
            "placeholder": "​",
            "style": "IPY_MODEL_35839cd4bb51425b93f200c129ac03a8",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "4a973c8bd37c4384b730aff3d06de702": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92e3f4c2e1c04ce8a43f9b9f62fb9472",
            "max": 636,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8be5e9127b014b9faba0500e1bfc221f",
            "value": 636
          }
        },
        "4bcdd4bc923a42da8bff933caf430f00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3379d7e766a648ea9ae8b923e92bc2cc",
            "placeholder": "​",
            "style": "IPY_MODEL_b3cb7e8a11124cbab82a99b930728a58",
            "value": " 17.5M/17.5M [00:00&lt;00:00, 34.2MB/s]"
          }
        },
        "50427b62d1b544b4b35c9694c13d515c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "527598fd38284ca68a1aa519f8593b5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "566eb64273f147e1a21f47bbffd3482f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbd715fc6e1b48fa862c2fe0ca6bb043",
            "max": 4241003,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d449650df6934520b2a98c496e5eed1c",
            "value": 4241003
          }
        },
        "582aea7e488648788b4ebfe4be4b9e3a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59df1810ce1c4e32b490edaa733895fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "74ae2cd78e7d4845a19d6b96e25b0e59": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_38025da459d045b2b07e8e86abc3d9d4",
              "IPY_MODEL_054976193f354b15aea67578cc2c460b",
              "IPY_MODEL_17af6bd8c0c042f2b04fb9d50cf0826b"
            ],
            "layout": "IPY_MODEL_d9a8765454a3432bbcf5e6504881746b"
          }
        },
        "75bf5666dc434ac3992712dc09f7c297": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6b510217227476d9ea2f54f89a06277",
            "placeholder": "​",
            "style": "IPY_MODEL_19e1320dd8d64a319370cc9b4fbe92b1",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "76fda341b04e4115a37ff8e424ae301f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "828f97535e7f488983d1bb9012f85bf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "835d7c99dd864d7db2b5d5ecee692155": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "88cdad6f949345c9827415e2520bda83": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_582aea7e488648788b4ebfe4be4b9e3a",
            "placeholder": "​",
            "style": "IPY_MODEL_f55dbef1ad9b4196a583432f5d131626",
            "value": " 636/636 [00:00&lt;00:00, 3.98kB/s]"
          }
        },
        "8be5e9127b014b9faba0500e1bfc221f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "92e3f4c2e1c04ce8a43f9b9f62fb9472": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f8800044ba84a8cb18d32af5eb697aa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6b510217227476d9ea2f54f89a06277": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0f499cfbb7640f6b975ecf7193709e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b235514c7eaa4129b188e04c8d055077": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb6a6cc12084405bbaa738030e3607fe",
            "placeholder": "​",
            "style": "IPY_MODEL_527598fd38284ca68a1aa519f8593b5f",
            "value": "tokenizer.model: 100%"
          }
        },
        "b3cb7e8a11124cbab82a99b930728a58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4cde882adb444699e8c9167cdce3dd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1899c8a19eb945559f8ec5ab4e4144c1",
              "IPY_MODEL_1d3e1c6fd5bc415d9d17b62e0879cb0e",
              "IPY_MODEL_4bcdd4bc923a42da8bff933caf430f00"
            ],
            "layout": "IPY_MODEL_50427b62d1b544b4b35c9694c13d515c"
          }
        },
        "bb6a6cc12084405bbaa738030e3607fe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1cd86885cb44c019e30aac5a63e07e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d449650df6934520b2a98c496e5eed1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d7db62b74f88459fb2aba7ab86664db1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b235514c7eaa4129b188e04c8d055077",
              "IPY_MODEL_566eb64273f147e1a21f47bbffd3482f",
              "IPY_MODEL_fd754cc986e84b9db1812550321d751d"
            ],
            "layout": "IPY_MODEL_9f8800044ba84a8cb18d32af5eb697aa"
          }
        },
        "d9a8765454a3432bbcf5e6504881746b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbd715fc6e1b48fa862c2fe0ca6bb043": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f55dbef1ad9b4196a583432f5d131626": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd754cc986e84b9db1812550321d751d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0f499cfbb7640f6b975ecf7193709e9",
            "placeholder": "​",
            "style": "IPY_MODEL_828f97535e7f488983d1bb9012f85bf4",
            "value": " 4.24M/4.24M [00:00&lt;00:00, 11.9MB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
